trigger:
  branches:
    include:
      - none

pr: none

pool:
  vmImage: ubuntu-latest

parameters:
  - name: repo_parent_folder
    type: string
    default: MLOpsFlow
  - name: date_filters
    type: string
    default: none
  - name: hyperparameters
    type: string
    default: none
  - name: pipeline_type
    type: string
    default: azdevops
  - name: organization
    type: string
    default: mlops-tiger
  - name: project_devops
    type: string
    default: mlcore

variables:
  - ${{ if eq(variables['Build.SourceBranch'], 'refs/heads/UAT')}}:
    - group: SDK-UAT
  - ${{ if eq(variables['Build.SourceBranch'], 'refs/heads/PROD')}}:
    - group: SDK-PROD
  - ${{ if eq(variables['Build.SourceBranch'], 'refs/heads/QA')}}:
    - group: SDK-QA
  - ${{ if not(or(eq(variables['Build.SourceBranch'], 'refs/heads/QA'), eq(variables['Build.SourceBranch'], 'refs/heads/UAT'), eq(variables['Build.SourceBranch'], 'refs/heads/PROD'))) }}:
    - group: SDK-DEV

stages:
  - stage: PublishToDBFS
    displayName: publish notebooks
    jobs:
      - job: Publish
        steps:
          - bash: pip install requests && pip install python-dotenv && pip install databricks-cli
            displayName: installing requests, python-dotenv and databricks-cli


          - script: |
              SUBSTRING=$(echo $(Build.Repository.Name)| cut -d'/' -f 2)
              echo $SUBSTRING
              echo "##vso[task.setvariable variable=projectName]$SUBSTRING"
            displayName: 'project name'

          - script: |
              sed -i 's|${ENV_VARIABLE}|$(DEPLOY_ENV)|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              sed -i 's|${PIPELINE_ID}|$(System.DefinitionId)|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              sed -i 's|${DATE_FILTERS}|${{ parameters.date_filters }}|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              sed -i 's|${HYPERPARAMETERS}|${{ parameters.hyperparameters }}|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              sed -i 's|${PIPELINE_TYPE}|${{ parameters.pipeline_type }}|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              sed -i 's|${ORGANIZATION}|${{ parameters.organization }}|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              sed -i 's|${DEVOPS_PROJECT}|${{ parameters.project_devops }}|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              sed -i 's|${CLUSTER_ID}|$(CLUSTER_ID)|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              sed -i 's|${TRAIN_PATH}|/Repos/${{ parameters.repo_parent_folder }}/$(projectName)/notebooks/Train|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              sed -i 's|${FEATURE_PIPELINE_PATH_FT}|/Repos/${{ parameters.repo_parent_folder }}/$(projectName)/notebooks/FeaturePipeline_FT|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              sed -i 's|${FEATURE_PIPELINE_PATH_GT}|/Repos/${{ parameters.repo_parent_folder }}/$(projectName)/notebooks/FeaturePipeline_GT|g' "$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml"
              python -c "import json, yaml; print(json.dumps(yaml.load(open('$(Build.SourcesDirectory)/azure-pipelines/pipeline_configs/train_config.yaml'), Loader=yaml.FullLoader)))" > train_config.json
            displayName: 'Update configs with Variables'

          - script: |
              databricks repos update --path /Repos/${{ parameters.repo_parent_folder }}/$(projectName) --branch $(BRANCH)
              databricks runs submit --json-file train_config.json
            displayName: 'Create Databricks Job'
            env:
              databricksAccessToken: $(DATABRICKS_TOKEN)
              